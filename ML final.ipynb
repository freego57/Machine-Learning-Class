{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  From the perspective of a social scientist, which models did we learn this semester that are useful for ruling out alternative explanations through control variables AND that allow us to observe substantively meaningful information from model coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression, logistic regression, ridge regression, lasso regression and decision tree model.\n",
    "The first 4 of these models give the coefficients of the independent variables and can show the relative importance of variables, and how each variable influences the dependent variable and therefore show the corrleation that could be useful for social scientists. Decision tree model is also easy to interpret as it splits the observations through several cutoff values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Describe the main differences between supervised and unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised learning, we have data that is well labeled (tagged with correct anwsers) and we use the data to train the model. The model learns from the labeled training data.\n",
    "While for unsupervised learning, the data we use is unlabelled, and the model needs to work on its own to find information and is therefore more subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Is supervised or unsupervised learning the primary approach that is used by machine learning practitioners?  For whatever approach you think is secondary, why would you use this approach (what's a good reason to use these kinds of models?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning is more used by machine learning practitioners.\n",
    "\n",
    "Unsupervised learning is useful in exploratory analysis because it can identify structure in data  automatically. For example, if an analyst wants to segment consumers, clustering would be a good starting point. In situations where it is impractical for a human to propose trends in the data, unsupervised learning can provide initial insights that can then be used to test individual hypotheses.\n",
    "Also, it is easier to obtain unlabeled data so unsupervised learning requires less in terms of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which unsupervised learning modeling approaches did we cover this semester?  What are the major differences between these techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning models: \n",
    "Principal Components Analysis, clustering(k-means clustering, hierarchical clustering), neural networks(MLP,CNN).\n",
    "These techniques have different use cases. \n",
    "Principal Components Analysis is mainly for reducing the dimension of the dataset and leaving only the most important information. \n",
    "K-means clustering and hierarchical clustering are 2 kinds of clustering techniques, they are used for grouping observations and making sure observations in each group are similar to each other while observations from different groups are more different.\n",
    "Neural networks are modelled in a way similar to human brain and is used for recognizing patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  What are the main benefits of using Principal Components Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PCA will reduce the dimension of the dataset. This is especially useful for removing correlated variables as all the principal components are independent of each other. And PCA will leave the important features.\n",
    "2. PCA can speed up the machine learning algorithms. With less variables, the training time of machine learning algrithms reduces significantly.\n",
    "3. PCA can help with the problem of overfitting. The model might have the problem of overfitting with too many variables included. By reducing the number of variables, and leaving only important features, the problem of overfitting can be alleviated.\n",
    "4. PCA can help improve visualization. When the dataset is in high dimensions, it's hard to visualize it. But if the dataset is transformed to 2 dimensions using PCA, it gets easier to visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Thinking about neural networks, what are three major differences between a deep multilayer perceptron network and a convolutional neural network model?  Be sure to define any key terms in your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For a deep multilayer perceptron network, layers are fully connected, which means that nodes in adjacent layers are connected with each other, the number of parameters can grow to very high,and redundancy is caused by such high dimensions. While for convolutional neural network, the convolutional layers are sparsely connected rather than fully connected and the redundancy can be avoided.\n",
    "2. Convolutional neural network also has pooling layers to scale down the parameters while conserving enough information. But this is not included in the deep multilayer perceptron network.\n",
    "3. Multilayer perceptron network cannot handle spatial information as it takes flattened vectors as input. While convolutional neural network takes matrices as well as vectors as input and therefore it can detect spatial patterns like edges, shapes and objects, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write the keras code for a multilayer perceptron neural network with the following structure: Three hidden layers.  50 hidden units in the first hidden layer, 100 in the second, and 150 in the third.  Activate all hidden layers with relu.  The output layer should be built to classify to five categories.  Further, your optimization technique should be stochastic gradient descent.  (This code should simply build the architecture of the model.  You will not run it on real data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 755       \n",
      "=================================================================\n",
      "Total params: 21,555\n",
      "Trainable params: 21,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "#initiate\n",
    "model = Sequential() \n",
    "#first hidden layer\n",
    "model.add(Dense(units=50, activation='relu', input_dim=10)) #input_dim=number of features in the dataset\n",
    "#second hidden layer\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "#third hidden layer\n",
    "model.add(Dense(units=150, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(units=5, activation='softmax'))  #use softmax to calculate 0 to 1 probabilities for each of 5 categories\n",
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write the keras code for a multilayer perceptron neural network with the following structure: Two hidden layers.  75 hidden units in the first hidden layer and 150 in the second.  Activate all hidden layers with relu.  The output layer should be built to classify a binary dependent variable.  Further, your optimization technique should be stochastic gradient descent.  (This code should simply build the architecture of the model.  You will not run it on real data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 75)                825       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 150)               11400     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 12,376\n",
      "Trainable params: 12,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#initiate\n",
    "model = Sequential() \n",
    "\n",
    "#first hidden layer\n",
    "model.add(Dense(units=75, activation='relu', input_dim=10)) #input_dim=number of features in the dataset\n",
    "#second hidden layer\n",
    "model.add(Dense(units=150, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "#compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.  Write the keras code for a convolutional neural network with the following structure: Two convolutional layers.  16 filters in the first layer and 28 in the second.  Activate all convolutional layers with relu.  Use max pooling after each convolutional layer with a 2 by 2 filter.  The output layer should be built to classify to ten categories.  Further, your optimization technique should be stochastic gradient descent.  (This code should simply build the architecture of the model.  You will not run it on real data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate\n",
    "model = Sequential()\n",
    "#first convolutional layer (2 by 2 filter for convolution and 2 by 2 filter for maxpooling)\n",
    "model.add(Conv2D(16, (2, 2),activation='relu',input_shape=(28,28,1)))  #input_shape is a make-up size of the input image\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#second convolutional layer (2 by 2 filter for convolution and 2 by 2 filter for maxpooling) \n",
    "model.add(Conv2D(28, (2, 2), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "#compile the cnn\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.  Write the keras code for a convolutional neural network with the following structure: Two convolutional layers.  32 filters in the first layer and 32 in the second.  Activate all convolutional layers with relu.  Use max pooling after each convolutional layer with a 2 by 2 filter.  Add two fully connected layers with 128 hidden units in each layer and relu activations.  The output layer should be built to classify to six categories.  Further, your optimization technique should be stochastic gradient descent.  (This code should simply build the architecture of the model.  You will not run it on real data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate\n",
    "model = Sequential()\n",
    "#first convolutional layer (2 by 2 filter for convolution and 2 by 2 filter for maxpooling)\n",
    "model.add(Conv2D(32, (2, 2),activation='relu',input_shape=(28,28,1)))  #input_shape is a make-up size of the input image\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#second convolutional layer (2 by 2 filter for convolution and 2 by 2 filter for maxpooling) \n",
    "model.add(Conv2D(32, (2, 2), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#2 fully connected layers\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "\n",
    "#compile the cnn\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
