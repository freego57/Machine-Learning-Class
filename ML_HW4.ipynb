{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML HW4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-jXaOYxMFdd",
        "colab_type": "text"
      },
      "source": [
        "## **Part 1: Build a classification model using text data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXpF2WiVG-Yp",
        "colab_type": "text"
      },
      "source": [
        "**Import the text data, vectorize the review column into an X matrix.  Then run at least three models and select a single best model.  Note that you can also create three models that simply use different types of explanatory variables such as a logistic regression with different n grams or different tokenizers.  Be sure to explain your choice and evaluate this model using the test set.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGa4m6ZtMO76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-7sh8MaWb0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8ca89df9-eb03-40cc-ad0d-42c080363efe"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/freego57/Machine-Learning-Class/master/HW4_Text_data.csv'\n",
        "text = pd.read_csv(url)\n",
        "text.head(5)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Recommended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"go to\" please offer a maxi for mature custome...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"go to\" tee for sz 10+ women.Women who want so...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"long and warm\".These leg warmers are perfect ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"tweed\" dress.I bought this dress for my siste...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#1 stunna.I am in lust with this fabulous dres...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Recommended\n",
              "0  \"go to\" please offer a maxi for mature custome...            1\n",
              "1  \"go to\" tee for sz 10+ women.Women who want so...            1\n",
              "2  \"long and warm\".These leg warmers are perfect ...            1\n",
              "3  \"tweed\" dress.I bought this dress for my siste...            1\n",
              "4  #1 stunna.I am in lust with this fabulous dres...            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mtjD5RyBx2t",
        "colab_type": "text"
      },
      "source": [
        "**Model 1 CountVectorizer with all default parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJvRhFI5Z8Pk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a57503f4-cc68-463a-d4a0-4815aa1095b9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text_train = text['Review']\n",
        "vect = CountVectorizer().fit(text_train)\n",
        "X = vect.transform(text_train)\n",
        "y=text['Recommended']\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16985, 13010)\n",
            "(16985,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThORO6oTs4eQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ff7ccdca-4a55-4c3a-c523-24e7f73bce46"
      },
      "source": [
        "# Set up training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12738, 13010)\n",
            "(12738,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O40D7MwDZydy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e871ebaa-e242-4149-aa9c-dd2c5e77546c"
      },
      "source": [
        "#train the model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5,scoring='f1',n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "print(\"Best parameters: \", grid.best_params_)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.94\n",
            "Best parameters:  {'C': 0.1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fat5d6yLknAu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfec4b58-ee10-4b14-e87e-0e59296be262"
      },
      "source": [
        "#cross validation on test data\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(LogisticRegression(C=0.1), X_test, y_test, cv=5,scoring='f1',n_jobs=-1)\n",
        "print(\"Mean cross-validation f1 score: {:.3f}\".format(np.mean(scores)))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cross-validation f1 score: 0.934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTGwtNn6CCtb",
        "colab_type": "text"
      },
      "source": [
        "**Model 2 CountVectorizer with min_df=10 and n-gram=(1,2)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rY3PqE6CvNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fff1dd9-8fe9-4b5f-d334-90d9fa5eaebb"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text_train = text['Review']\n",
        "vect = CountVectorizer(min_df=10,ngram_range=(1,2)).fit(text_train)\n",
        "X = vect.transform(text_train)\n",
        "y=text['Recommended']\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16985, 15906)\n",
            "(16985,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d08_KHnjDCQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0cf1cbc2-6ad2-49dc-c9fe-23de48055783"
      },
      "source": [
        "# Set up training and test data \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12738, 15906)\n",
            "(12738,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a643rkJiDHjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d4647df7-c1a9-4f7b-a0bc-e8740aed938e"
      },
      "source": [
        "#train the model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5,scoring='f1',n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "print(\"Best parameters: \", grid.best_params_)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.94\n",
            "Best parameters:  {'C': 0.1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nWyNbySpBSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3af48cb-4219-4e11-b7b4-24c72bc87aeb"
      },
      "source": [
        "#cross validation on test data\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(LogisticRegression(C=0.1), X_test, y_test, cv=5,scoring='f1',n_jobs=-1)\n",
        "print(\"Mean cross-validation f1 score: {:.3f}\".format(np.mean(scores)))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cross-validation f1 score: 0.936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1haJdKjDS35",
        "colab_type": "text"
      },
      "source": [
        "**Model 3 TfidfVectorizer with min_df=5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJp40ufQDaEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5d6e1e3d-fefd-4ecd-ed0c-7432c34eb94b"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "text_train = text['Review']\n",
        "vect = TfidfVectorizer(min_df=5).fit(text_train)\n",
        "X = vect.transform(text_train)\n",
        "y=text['Recommended']\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16985, 4396)\n",
            "(16985,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6_pTVD3D_mo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "517dc8cd-ad65-4ff1-f533-b37a121503d7"
      },
      "source": [
        "# Set up training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12738, 4396)\n",
            "(12738,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74aPw7fWEHR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "426439de-6bbc-4821-b347-6e514f7f82c1"
      },
      "source": [
        "#train the model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5,scoring='f1',n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "print(\"Best parameters: \", grid.best_params_)\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.94\n",
            "Best parameters:  {'C': 10}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EaA72O9pYce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdadd01d-e930-458e-b289-9f00b0d6b21f"
      },
      "source": [
        "#cross validation on test data\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "scores = cross_val_score(LogisticRegression(C=10), X_test, y_test, cv=5,scoring='f1',n_jobs=-1)\n",
        "print(\"Mean cross-validation f1 score: {:.3f}\".format(np.mean(scores)))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cross-validation f1 score: 0.935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWgB22QnrOws",
        "colab_type": "text"
      },
      "source": [
        "**The best model of the three is model 2--CountVectorizer with min_df=10 and n-gram=(1,2), it has the highest f1 score on test dataset, which shows that it can provide the best prediction for this imbalanced dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcU_DYGBvtHK",
        "colab_type": "text"
      },
      "source": [
        "## **Part 2: Build a predictive neural network using Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvYMQ7JxBp2z",
        "colab_type": "text"
      },
      "source": [
        "**Run a multilayer perceptron (feed forward neural network) with two hidden layers on the iris dataset using the keras Sequential interface.Include code for selecting the number of hidden units using GridSearchCV and evaluation on a test-set.  Describe the differences in the predictive accuracy of models with different numbers of hidden units.  Describe the predictive strength of your best model.  Be sure to explain your choice and evaluate this model using the test set.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_GcH63bwx0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c53e746d-1bc8-4e00-ee78-ee33c7bd884a"
      },
      "source": [
        "iris=pd.read_csv('http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv')\n",
        "iris=iris.drop(['Unnamed: 0'], axis=1)\n",
        "print(iris.Species.nunique())  #3 species\n",
        "print(iris.head(5))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhI2A9QAbl9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = iris.loc[:, iris.columns != 'Species']\n",
        "y = iris['Species']"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hxuUW4G2qwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_y= LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)  #label y's each category to 0,1,2\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=3,dtype=int)  #to an array with 3 columns with 0/1 encoded\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6aW3Ckj04mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split to train and test data and scale the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train=StandardScaler().fit_transform(X_train)\n",
        "X_test=StandardScaler().fit_transform(X_test)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZxSKaNcymCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(hiddennodes):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(hiddennodes, input_dim=4, activation='relu'))\n",
        "\tmodel.add(Dense(hiddennodes, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, verbose=0)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWODIszwjG8c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d18671cf-ed24-47d4-9740-d2129e348b92"
      },
      "source": [
        "#using GridSearchCV to find the best hiddennodes numbers\n",
        "hiddennodes = [5,10,15,20,25,30] \n",
        "param_grid = dict(hiddennodes=hiddennodes)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.883399 using {'hiddennodes': 25}\n",
            "0.765613 (0.124657) with: {'hiddennodes': 5}\n",
            "0.865217 (0.069462) with: {'hiddennodes': 10}\n",
            "0.828854 (0.079422) with: {'hiddennodes': 15}\n",
            "0.855731 (0.097204) with: {'hiddennodes': 20}\n",
            "0.883399 (0.061817) with: {'hiddennodes': 25}\n",
            "0.874704 (0.052072) with: {'hiddennodes': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OK_BFky-qsP",
        "colab_type": "text"
      },
      "source": [
        "***The best model is with 25 hiddennodes in each layer, with the highest accuracy of 0.883, other models all have lower average accuracy ranging from 0.766 to 0.875. ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_KfVWSM4gfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "980c8910-7078-4a3b-e832-64577437fa87"
      },
      "source": [
        "#model with 25 nodes per layer\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=4, activation='relu'))\n",
        "model.add(Dense(25, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size = 30, epochs = 100)\n",
        "\n",
        "#evaluate prediction error on test data\n",
        "print(\"test-set score: {:.3f}\".format(grid.score(X_test, y_test)))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 0s 420us/step - loss: 1.1845 - accuracy: 0.2768\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 51us/step - loss: 1.1502 - accuracy: 0.3214\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 48us/step - loss: 1.1188 - accuracy: 0.3571\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 49us/step - loss: 1.0895 - accuracy: 0.3750\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 56us/step - loss: 1.0622 - accuracy: 0.4554\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 52us/step - loss: 1.0369 - accuracy: 0.4911\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 62us/step - loss: 1.0127 - accuracy: 0.5982\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 69us/step - loss: 0.9887 - accuracy: 0.6964\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 77us/step - loss: 0.9664 - accuracy: 0.7143\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 63us/step - loss: 0.9447 - accuracy: 0.6964\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 64us/step - loss: 0.9240 - accuracy: 0.6875\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 56us/step - loss: 0.9043 - accuracy: 0.6786\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 61us/step - loss: 0.8846 - accuracy: 0.7143\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 64us/step - loss: 0.8655 - accuracy: 0.7232\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 67us/step - loss: 0.8473 - accuracy: 0.7321\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 77us/step - loss: 0.8301 - accuracy: 0.7589\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 75us/step - loss: 0.8136 - accuracy: 0.7768\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 65us/step - loss: 0.7977 - accuracy: 0.8036\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 80us/step - loss: 0.7816 - accuracy: 0.8125\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 66us/step - loss: 0.7666 - accuracy: 0.8125\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 67us/step - loss: 0.7515 - accuracy: 0.8125\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 89us/step - loss: 0.7375 - accuracy: 0.8125\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 70us/step - loss: 0.7237 - accuracy: 0.8125\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 75us/step - loss: 0.7108 - accuracy: 0.8125\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 78us/step - loss: 0.6984 - accuracy: 0.8125\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 72us/step - loss: 0.6858 - accuracy: 0.8125\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 77us/step - loss: 0.6741 - accuracy: 0.8214\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 94us/step - loss: 0.6626 - accuracy: 0.8214\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 66us/step - loss: 0.6518 - accuracy: 0.8214\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 68us/step - loss: 0.6411 - accuracy: 0.8214\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 71us/step - loss: 0.6307 - accuracy: 0.8214\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 63us/step - loss: 0.6210 - accuracy: 0.8214\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 58us/step - loss: 0.6114 - accuracy: 0.8214\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 61us/step - loss: 0.6021 - accuracy: 0.8214\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 76us/step - loss: 0.5935 - accuracy: 0.8214\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 55us/step - loss: 0.5851 - accuracy: 0.8214\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 68us/step - loss: 0.5769 - accuracy: 0.8214\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 80us/step - loss: 0.5691 - accuracy: 0.8214\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 80us/step - loss: 0.5618 - accuracy: 0.8214\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 79us/step - loss: 0.5539 - accuracy: 0.8304\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 71us/step - loss: 0.5469 - accuracy: 0.8304\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 54us/step - loss: 0.5402 - accuracy: 0.8393\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 62us/step - loss: 0.5334 - accuracy: 0.8393\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 72us/step - loss: 0.5268 - accuracy: 0.8393\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 60us/step - loss: 0.5206 - accuracy: 0.8393\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 72us/step - loss: 0.5146 - accuracy: 0.8393\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 69us/step - loss: 0.5086 - accuracy: 0.8393\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 81us/step - loss: 0.5029 - accuracy: 0.8393\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 74us/step - loss: 0.4975 - accuracy: 0.8393\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 69us/step - loss: 0.4919 - accuracy: 0.8393\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 78us/step - loss: 0.4869 - accuracy: 0.8393\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 74us/step - loss: 0.4816 - accuracy: 0.8393\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 89us/step - loss: 0.4768 - accuracy: 0.8393\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 89us/step - loss: 0.4718 - accuracy: 0.8393\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 76us/step - loss: 0.4672 - accuracy: 0.8393\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 55us/step - loss: 0.4625 - accuracy: 0.8393\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 100us/step - loss: 0.4582 - accuracy: 0.8393\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 64us/step - loss: 0.4539 - accuracy: 0.8393\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 64us/step - loss: 0.4497 - accuracy: 0.8393\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 85us/step - loss: 0.4456 - accuracy: 0.8393\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 67us/step - loss: 0.4415 - accuracy: 0.8393\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 87us/step - loss: 0.4376 - accuracy: 0.8482\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 64us/step - loss: 0.4334 - accuracy: 0.8482\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 68us/step - loss: 0.4294 - accuracy: 0.8571\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 70us/step - loss: 0.4255 - accuracy: 0.8661\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 73us/step - loss: 0.4220 - accuracy: 0.8571\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 67us/step - loss: 0.4181 - accuracy: 0.8661\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 71us/step - loss: 0.4142 - accuracy: 0.8571\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 64us/step - loss: 0.4108 - accuracy: 0.8571\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 77us/step - loss: 0.4072 - accuracy: 0.8571\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 78us/step - loss: 0.4038 - accuracy: 0.8571\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 63us/step - loss: 0.4007 - accuracy: 0.8571\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 0s 58us/step - loss: 0.3969 - accuracy: 0.8571\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 69us/step - loss: 0.3935 - accuracy: 0.8571\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 69us/step - loss: 0.3903 - accuracy: 0.8571\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 72us/step - loss: 0.3871 - accuracy: 0.8571\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 57us/step - loss: 0.3841 - accuracy: 0.8571\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 55us/step - loss: 0.3809 - accuracy: 0.8571\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 58us/step - loss: 0.3779 - accuracy: 0.8661\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 58us/step - loss: 0.3750 - accuracy: 0.8661\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 65us/step - loss: 0.3723 - accuracy: 0.8661\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 67us/step - loss: 0.3693 - accuracy: 0.8661\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 74us/step - loss: 0.3666 - accuracy: 0.8661\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 75us/step - loss: 0.3639 - accuracy: 0.8661\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 90us/step - loss: 0.3614 - accuracy: 0.8661\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 75us/step - loss: 0.3585 - accuracy: 0.8750\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 61us/step - loss: 0.3563 - accuracy: 0.8750\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 60us/step - loss: 0.3535 - accuracy: 0.8750\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 54us/step - loss: 0.3511 - accuracy: 0.8750\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 58us/step - loss: 0.3486 - accuracy: 0.8750\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 58us/step - loss: 0.3461 - accuracy: 0.8750\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 55us/step - loss: 0.3439 - accuracy: 0.8839\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 59us/step - loss: 0.3417 - accuracy: 0.8839\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 59us/step - loss: 0.3392 - accuracy: 0.8839\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 59us/step - loss: 0.3370 - accuracy: 0.8839\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 57us/step - loss: 0.3350 - accuracy: 0.8839\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 56us/step - loss: 0.3326 - accuracy: 0.8839\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 53us/step - loss: 0.3305 - accuracy: 0.8839\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 90us/step - loss: 0.3284 - accuracy: 0.8839\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 79us/step - loss: 0.3263 - accuracy: 0.8839\n",
            "test-set score: 0.895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3UV7ymCCVqQ",
        "colab_type": "text"
      },
      "source": [
        "**The model on the test dataset has an accuracy score of 0.895.**"
      ]
    }
  ]
}